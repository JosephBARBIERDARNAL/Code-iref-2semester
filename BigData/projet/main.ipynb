{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911fd9a2-7ea5-4c1d-baf3-44db0c6f33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "#mask warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import our functions\n",
    "from functions import *\n",
    "\n",
    "#get path\n",
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec7c02d-2c8e-4e57-a511-6914a5717f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_CARRIERE          0.000000\n",
      "date_debut           0.000000\n",
      "date_fin             0.000000\n",
      "ETAT                 0.000000\n",
      "CATEGORIE_EMPLOI     0.020218\n",
      "QUALITE              0.027084\n",
      "STATUT_AGENT         0.026512\n",
      "INDICE_BRUT         20.959779\n",
      "code                54.151396\n",
      "libelle              3.948978\n",
      "Unnamed: 10         99.528026\n",
      "Unnamed: 11         99.997330\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "#df des individus \n",
    "df = pd.read_csv(f\"{path}/20ksample.csv\", encoding='latin-1', low_memory=False)\n",
    "#df = pd.read_csv(f\"{path}/100ksample.csv\", sep=\";\", encoding='latin-1', low_memory=False)\n",
    "\n",
    "#clean df and save it\n",
    "df = df.rename(columns={'LIBELLE_EMPLOI_GRADE': 'libelle', 'EMPLOI_STATUTAIRE':'code'})\n",
    "print(df.isna().sum()/len(df)*100, \"%\")\n",
    "df.libelle = df.libelle.astype('category')\n",
    "df['libelle'] = df['libelle'].apply(clean_libelle)\n",
    "df.to_csv(\"clean20K.csv\", index=False)\n",
    "\n",
    "#subset 2011\n",
    "df = pd.read_csv(f\"{path}/clean20k.csv\", encoding='latin-1', low_memory=False)\n",
    "df.libelle = df.libelle.astype(\"str\")\n",
    "df['date_fin'] = pd.to_datetime(df['date_fin'], format='%d/%m/%Y')\n",
    "df['date_debut'] = pd.to_datetime(df['date_debut'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b0314b-1cf1-43f9-958f-9f2c570d1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT DES EXEMPLES DU NETTOYAGE DE LIBELLÉS\n",
    "n = 1000\n",
    "df_random = df.sample(n)\n",
    "#for i in range(n):\n",
    "#    print(f\"{df_random.libelle.iloc[i]}\\n->{df_random.libelle2.iloc[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d15e9-8718-4101-b8e5-2a42d7a1a881",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Correction des libellés\n",
    "\n",
    "##### Parmi l'ensemble des individus, si un code un présent, alors on va chercher dans la nomenclature le libelle correspondant. Cela a pour objectif d'augmenter le nombre d'individus avec un libellé standardisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bf196f-b3c1-44cc-87a7-9922ec31755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open nomenclature\n",
    "nomenclature = pd.read_csv(f\"{path}/nomenclature.csv\")\n",
    "\n",
    "#rename colonnes et convert to string\n",
    "nomenclature = nomenclature.rename(columns={'libelle_NEG_rempl': 'libelle', 'code_NETH_rempl':'code'})\n",
    "nomenclature.libelle = nomenclature.libelle.astype(\"str\")\n",
    "\n",
    "#clean libellés de la nomenclature\n",
    "nomenclature['libelle'] = nomenclature['libelle'].apply(clean_libelle)\n",
    "\n",
    "#faire un set de la nomenclature\n",
    "set_nomenclature = set(nomenclature.libelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb921ec-9c78-4f73-a02c-b84ee7c8fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remplacer libelle (si code, alors mettre le libelle standardisé)\n",
    "df = remplacer_libelles(df, nomenclature, \"code\", \"libelle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc71589-1113-4f8c-94af-f9b7abbf9e2b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Approximation des libellés non-standard\n",
    "\n",
    "##### Parmi les libellés non-standardisés restant, on souhaite, à remplacer par un libellé standardisé. Pour cela, on doit calculer une similarité entre les libellés standardisés et non-standardisés. Pour cela il faut d'abord vectorizer les libellés, nous avons utilisés différentes méthodes :\n",
    "- Count vectorizer \n",
    "- Tfidf vectorizer \n",
    "- Hashing vectorizer\n",
    "\n",
    "##### Méthode de similarité testée :\n",
    "- [similarité cosinus](https://fr.wikipedia.org/wiki/Similarité_cosinus) (cosinus de l'angle entre 2 vecteurs de dimensions n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f1b9b6-a330-4f73-8d4d-1b7cefb1e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample from the df with the observations\n",
    "n = 3000\n",
    "non_standard_labels = list(df.libelle.sample(n))\n",
    "\n",
    "#definir libellés standards et non standards\n",
    "non_standard_labels = list(df.libelle)\n",
    "standard_labels = list(set_nomenclature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdc2ab8-a12c-4067-a428-d3bc574decb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a vectorizer\n",
    "vectorizer1 = CountVectorizer()\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "vectorizer3 = HashingVectorizer()\n",
    "X_non_standard = vectorizer3.fit_transform(non_standard_labels)\n",
    "X_standard = vectorizer3.transform(standard_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f004489-5d8d-4204-b3d2-dbd6dcd10cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1048575/1048575 [00:55<00:00, 18945.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (sec): 193.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#compute cosine similarity for each obs for each libelle standardisé\n",
    "start = time.time()\n",
    "\n",
    "#calcul de la matrice de cosinus similarité\n",
    "similarity_matrix = cosine_similarity(X_non_standard, X_standard)\n",
    "\n",
    "#initialiser la liste des nouveaux libellés\n",
    "most_similar_labels = []\n",
    "for i in tqdm(range(len(non_standard_labels))):\n",
    "    \n",
    "    #si nan, alors on passe\n",
    "    if non_standard_labels[i] == \"nan\":\n",
    "        most_similar_labels.append(np.nan)\n",
    "    \n",
    "    #sinon, on prend la plus grande similarité\n",
    "    else:\n",
    "        most_similar_index = similarity_matrix[i].argmax()\n",
    "        most_similar_label = standard_labels[most_similar_index]\n",
    "        #print(f\"{non_standard_labels[i]}\\n-> {most_similar_label}\\n\\n\")\n",
    "        most_similar_labels.append(most_similar_label)\n",
    "    \n",
    "end = time.time()\n",
    "print(f\"Time (sec): {round(end - start,2)}\")\n",
    "\n",
    "#ajouter les nouveaux labels\n",
    "df.libelle = most_similar_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101a954b-2ec6-4873-a88a-a9dc2addf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on enregistre le nouveau df 20k\n",
    "df.to_csv(\"clean20K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c10c18-b71d-4f5c-82bd-b71185f39b67",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Deduction des codes grâce aux nouveaux libellés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81225014-a95a-4fb4-85c6-634ba2101ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_CARRIERE          0.000000\n",
      "date_debut           0.000000\n",
      "date_fin             0.000000\n",
      "ETAT                 0.000000\n",
      "CATEGORIE_EMPLOI     0.020218\n",
      "QUALITE              0.027084\n",
      "STATUT_AGENT         0.026512\n",
      "INDICE_BRUT         20.959779\n",
      "code                54.151396\n",
      "libelle              5.308538\n",
      "Unnamed: 10         99.528026\n",
      "Unnamed: 11         99.997330\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m2/jfzxyg4s0xz3jyw5f94r7tcm0000gn/T/ipykernel_15069/3973648219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ajouter les codes à partir des libellés\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mna1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremplacer_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnomenclature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"libelle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mna2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/M1S2/bigdata/Projet/functions.py\u001b[0m in \u001b[0;36mremplacer_code\u001b[0;34m(df_base, df_nomenclature, code, libelle)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremplacer_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_nomenclature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibelle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdict_nomenclature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_nomenclature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlibelle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_nomenclature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mdf_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlibelle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_nomenclature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5573\u001b[0m         ):\n\u001b[1;32m   5574\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'fill'"
     ]
    }
   ],
   "source": [
    "#ouvrir le df et afficher nan\n",
    "df = pd.read_csv(\"clean20K.csv\", low_memory=False)\n",
    "print(df.isna().sum()/len(df)*100)\n",
    "\n",
    "#ajouter les codes à partir des libellés\n",
    "na1 = df.isna().sum().sum()\n",
    "df = remplacer_code(df, nomenclature, \"code\", \"libelle\")\n",
    "na2 = df.isna().sum().sum()\n",
    "\n",
    "#print nan enlevés\n",
    "print(f\"Nombre de Nan enlevés: {na1-na2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65212e-195e-43cb-88b0-2dc923195a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean20K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2af43-69e3-4c3e-b056-50145b1ffaf0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Remplissage indice brut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24163d-74c5-4cb7-ab5e-47809d136bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean20K.csv\", low_memory=False)\n",
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438f376-67fb-4ae2-bbd1-99f392fcbeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a9540-cc2f-4364-984b-fc7ea1b34af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5bd13-d797-470f-89d9-bc39c57ba2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c6de2-b60b-46e7-a559-63021910ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de595430-1ad5-4f4c-b2fb-741af63ac233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0f137-59cc-40ae-b869-3b4e346224cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f807ab9-97ad-490e-8c64-4e9acf36ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2224a-9f0f-4ee6-889a-d87a13bee9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e889ac1-ce2f-4287-bde6-ebf7e5e090cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72478ea-d3fa-4320-a1d0-5d761bfb5c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
