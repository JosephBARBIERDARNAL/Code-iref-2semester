---
title: "Série temporelle : taux d'épargne des Pays-Bas depuis 1969"
author: "Barbier--Darnal Joseph"
output: pdf_document
---

# Introduction

### A propos des Pays-Bas

Les deux crises pétrolières des années 70 ont provoqué une flambée des prix de l'énergie, une inflation élevée et une récession économique mondiale. Les pays occidentaux ont cherché à diversifier leurs sources d'énergie et à améliorer l'efficacité énergétique pour réduire leur dépendance au pétrole étranger. Malgré la découverte du gisement de Groningue au nord des Pays-Bas en 1959, impliquant une explosion de la production de gaz naturel jusqu'en 1977 au sein du pays$^1$, les crises pétrolières prouvèrent l'importance des hydrocarbures, ne permettant pas aux Pays-Bas d'échapper à la règle. 

La découverte du gisement de Groningue a également eu de faire apparaître le terme de "*mal hollandais*", désignant l'impact de l'exploitation de ressources naturelles sur l'industrie manufaturière locale. Le fort accroissement des recettes d'exportations de gaz naturel provoqua une forte appréciation de la devise hollandaise, nuisant alors à la compétitivité-prix des exportations non liées au gaz naturel des Pays-Bas$^2$. 

Aujourd'hui, les Pays-Bas profitent fortement des échanges commerciaux internationnaux, notamment grâce au domaine agricole/maraîcher et sont une place financière mondiale, s'illustrant par les performances similaires de l'AEX index (25 plus grosses capitalisations des entreprises néerlandaises) et le Dow Jones ou le CAC 40. Les Pays-Bas sont aussi parfois qualifiés de "paradis fiscal qui ne dit pas son nom", en permettant par exemple à l'entreprise Nike de ne payer que 2% d'impôts sur les bénéfices grâce à sa filiale locale. 

En résumé, l'économie hollandaise a évolué de manière significative au fil des ans, passant d'une économie agricole à une économie manufacturière et de services avancée et diversifiée, avec une ouverture accrue aux marchés internationaux.

### Données du taux d'épargne

Les données utilisées ici représentent le taux d'épargne annuel des Pays-Bas entre 1969 et 2021, en pourcentage du PIB. On affiche ici les premières valeurs de cette série.

```{r message=FALSE, warning=FALSE, include=FALSE}
setwd("/Users/josephbarbier/Desktop/M1S2/série temp/projet")
rm(list=ls())

#packages
library(readxl)
library(ggplot2)
library(dplyr)
library(plotly)
library(urca)
library(stats)
library(fpp2)
library(forecast)
library(lmtest)
library(TSA)
library(tseries)
library(knitr)
library(CADFtest)
library(foreach)
library(doSNOW)
library(parallel)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#open series about Netherlands saving rate
savings = t(read_excel("taux-epargne.xls"))
colnames(savings) = paste(as.character(savings[1,]),as.character(savings[2,])) 

#keep only information needed
savings = as.data.frame(savings[-c(1,2),])
savings = subset(savings, select = c("Netherlands NLD", "Country Name Country Code"))

#change index and column names
colnames(savings) = c("Saving rate", "Date")
savings = subset(savings, Date > 1968)
rownames(savings) = 1:nrow(savings)

#converting to time series
savings$Date = as.integer(savings$Date)
savings$`Saving rate` = as.numeric(savings$`Saving rate`)
ts = ts(savings$`Saving rate`, freq=1, start=1969)

temp_df = round(savings,2)
kable(t(head(temp_df, n = 8)))
```
















\newpage

# Description de la série

### Statistiques descriptives

```{r echo=FALSE, message=FALSE, warning=FALSE, results = 'asis'}
cat("Moyenne sur la période :", round(mean(ts),2), "\n")
cat("\n")
cat("Medianne sur la période :", round(median(ts),2), "\n")
cat("\n")
cat("Ecart-type sur la période :", round(sd(ts),2))
```

Une moyenne et une médianne proches peut suggérer une distribution symétrique et donc, éventuellement, une distribution normale pour la série. On décide d'afficher l'histogramme des valeurs de la série afin d'obtenir une information supplémentaire sur la distribution.

### Estimation de la densité par noyau du taux d'épargne des Pays-Bas

###### (sur la période 1969-2021)

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.align='center', fig.height=8}
savings %>%
  ggplot( aes(x=`Saving rate`)) +
    geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
    theme_classic() +
    ggtitle("")
```

\

La distribution de la série temporelle du taux d'épargne de la Hollande entre 1969 et 2021 semble être légèrement asymétrique vers la droite. L'écart-type de 2.21 suggère que les valeurs sont relativement regroupées autour de la moyenne, bien que certains points de données soient assez éloignés de la moyenne, notamment supérieurs. Cela peut indiquer une certaine variabilité dans les comportements d'épargne des ménages hollandais au fil du temps.

\newpage

### Chronogramme du taux d'épargne des Pays-Bas

###### (sur la période 1969-2021)

```{r echo=FALSE, fig.align='center', fig.height=8, fig.width=12, message=FALSE, warning=FALSE}
savings %>% 
  ggplot(aes(x=Date, y=`Saving rate`)) +
    geom_line(color="#69b3a2") +
    ylim(20,33) +
    annotate(geom="text", x=1974, y=30.5, label="Première crise pétrolière") +
    annotate(geom="point", x=1973, y=30, size=10, shape=21, fill="transparent") +
    annotate(geom="text", x=1976.5, y=23.5, label="Deuxième crise pétrolière") +
    annotate(geom="point", x=1978, y=22.8, size=10, shape=21, fill="transparent") +
    geom_hline(yintercept=median(savings$`Saving rate`), color="orange", size=.5) + 
    geom_segment(x = 2016, y = 23, xend = 2019, yend = 25.5, arrow = arrow(length = unit(0.3, "cm"))) +
    annotate(geom="text", x=2015, y=22.5, label="Taux d'épargne médian au cours de la période") +
    annotate(geom="point", x=2007, y=27, size=10, shape=21, fill="transparent") +
    annotate(geom="text", x=2007, y=27.5, label="Crise des subprimes") +
    theme_bw()
```

\

Le taux d'épargne de la Hollande s'est vu diminué durant l'entièreté des années 70, notamment en suivant de la première crise pétrolière. Au global, la tendance est légèrement baissière. 

On peut remarquer le taux d'épargne, après la deuxième crise pétrolière, a eu du mal a dépassé la valeur médianne de la période. Cependant, depuis 2010, il est resté au dessus. 






















\newpage

# Stationnarité de la série

On cherche à savoir si le PGD générateur de nos données est stationnaire. 

### Test de Dickey-Fuller

Dans le modèle suivant : 
$$\Delta X_t = (\rho-1)X_{t-1} + \beta_0 + \beta_1 tendance_t + \varepsilon_t$$

On cherche à tester l'hypothèse suivante :

- H$_0$ : $\rho -1 = 0$ et  $\beta_1 =0$
- H$_1$ : $\mid \rho \mid < 1$ et $\beta_1 \neq 0$

Sous $H_0$, la statistique associée à $\beta_1$ suit une loi de Student à $n-k-1$ degrés de liberté. Pour la statistique associée à $\rho -1$, on compare cette dernière aux valeurs critiques calculées par Dickey et Fuller. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(ur.df(ts, type = "trend", lags = 0))
```

\

La valeur de $\beta_1$ est significativement différente de $0$ ($p<0.05$). On conlut alors à la présence d'une tendance dans la série. Egalement, la statistique associée à $\rho-1$ étant supérieure à la valeur critique au seuil de risque de $5\%$ ($-3.2821 > -3.45$), on accepte l'hypothèse nulle de présence d'une racine unitaire. Le PGD est alors DS. 

On cherche maintenant à savoir s'il y a de l'autocorrélation dans les résidus de ce modèle afin de vérifier la validation des conclusions précédentes. 

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
plot(ur.df(ts, type = "trend", lags = 0))
```

On remarque ici la présence d'autocorrélation et d'autocorrélation partielle dans les résidus du modèle, ce qui rend invalide les résultats du test de Dickey-Fuller précédent. On réalise alors le test de Dickey-Fuller Augmenté, en ajoutant des variables explicatives afin de prendre en compte cette autocorrélation. 

\

### Test de Dickey-Fuller Augmenté

La nouvelle spécification du modèle devient (au retard $p$)
$$X_t = (\rho-1) X_{t-1} + \beta_0 + \beta_1 tendance_t + \sum_{j=1}^p\gamma_j\Delta_{X_{t-j}} + \varepsilon_t$$


```{r echo=TRUE, fig.align='center', message=FALSE, warning=FALSE}
pmax = as.integer(12*(length(ts)/100)^(0.25)) #formule de Schwert
summary(CADFtest(ts, criterion="MAIC", type="trend", max.lag.y=pmax))
```

\

Comme la valeur donnée par `R` pour `Max lag of the diff. dependent variable` est de $0$, on utilise le critère du $BIC$ dans le test de Dickey-Fuller avec `pmax` explicatives supplémentaires au maximum. 

```{r echo=TRUE, fig.align='center', message=FALSE, warning=FALSE}
summary(ur.df(ts, type = "trend", lags = pmax-1))
```

La valeur de la statistique associé à $\mid\gamma_9\mid$ étant supérieure à $mid1.6$, on garde cette spécification. On conlut également que $\beta_1$ est différent de $0$ ($p<0.05$). La statistique associée à $\rho-1$ étant supérieure à celle calculée tabulée ($-2.493 > -3.45$), on conclut que le PGD est DS et on accepte l'hypothèse nulle de présence d'une racine unitaire. 

On vérifie qu'il n'y a plus d'autocorrélation dans les résidus. 

```{r echo=TRUE, fig.align='center', message=FALSE, warning=FALSE}
plot(ur.df(ts, type = "trend", lags = pmax-1))
```

Les conclusions du test de Dickey-Fuller étant valides, la bonne spécification du modèle s'écrit alors
$$X_t = (\rho-1)X_{t-1} + \beta_0 + \beta_1 tendance_t + \sum_{j=1}^9\gamma_j\Delta_{X_{t-j}} + \varepsilon_t$$

### Test de Zivot et Andrews

Pour la réalisation de ce test, on propose le modèle suivant 
$$X_t = \beta_0 + \beta_1t + \rho X_{t-1} + \delta_1 DU_t(T_B) + \delta_2 DT_t(T_B) + \sum_{j=1}^p\gamma_j\Delta_{X_{t-j}} + \varepsilon_t$$

On cherche à tester l'hypothèse suivante :

- H$_0$ : $\rho = 1$ (DS sans changement structurel)
- H$_1$ : $\mid \rho \mid < 1$ (TS avec un unique changement structurel)

La statistique de test utilisée est :

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(ur.za(ts, model="intercept", lag=pmax-1))
```

Seul $\delta_1$ est significatif, avec $\gamma_9$ le dernier coefficient significatif. On garde donc la spécification suivante
$$X_t = \beta_0 + \beta_1t + \rho X_{t-1} + \delta_1 DU_t(T_B) + \sum_{j=1}^9\gamma_j\Delta_{X_{t-j}} + \varepsilon_t$$

Comme la statistique calculée est supérieure à la valeur critique ($-4.2523 > -4.8$), on accepte $H_0$ : DS sans changement structurel. 

### Test de Lee et Strazicich



```{r message=FALSE, warning=FALSE, include=FALSE}
source("~/Desktop/M1S2/série temp/LeeStrazicichUnitRoot-master/LeeStrazicichUnitRootTest.R", encoding = 'UTF-8')
source("~/Desktop/M1S2/série temp/LeeStrazicichUnitRoot-master/LeeStrazicichUnitRootTestParallelization.R", encoding = 'UTF-8')
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
breaks = 1
model = "crash"
lags = pmax
cl = makeCluster(max(1, detectCores() - 1))
registerDoSNOW(cl)
#myLS_test = ur.ls.bootstrap(y=ts, model=model, breaks=breaks, lags=lags, method="GTOS", critval = "bootstrap")
```

### Stationnarisation de la série



\newpage

# Détection d'autocorrélation

On cherche à savoir si notre série est autocorrélée, et si oui, à quel(s) ordre(s). 

### Fonction d'autocorrélation

```{r echo=FALSE, fig.align='left', message=FALSE, warning=FALSE, fig.width=7, fig.height=3}
ggAcf(ts) + theme_bw() + ggtitle("")
```

D'après le graphique de l'ACF, notre série est autocorrélée à l'ordre 1, 2, 3 et 4. Cette information nous ait donnée par le fait que l'autocorrélation à l'ordre 1, 2, 3 et 4 dépasse le seuil donné (ici $\alpha =5\%$). On peut alors envisager une $MA(4)$ pour cette série.

\

### Fonction d'autocorrélation partielle 

```{r echo=FALSE, fig.align='left', message=FALSE, warning=FALSE, fig.width=7, fig.height=3}
ggPacf(ts) + theme_bw() + ggtitle("")
```

Lorsque l'on s'intéresse à l'autocorrélation partielle, et donc en prenant en compte les termes d'un décalage inférieur, la PACF nous indique qu'un $AR(1)$ serait pertinent puisque que la série est partiellement autocorrélée uniquement à l'ordre $1$. 

\newpage

### Test d'autocorrélation de Ljung-Box

On cherche à trouver les ordres pour lesquels notre série est autocorrélée. Pour cela, on effectue le test :

- H$_0$ : $\rho(1) = \rho(2) = \dots = \rho(K) =0$
- H$_1$ : Au moins un des $\rho(k) \neq 0$

La statistique de test utilisée est :
$$Q_K = T(T+1) \sum_{k=1}^{K} \frac{\hat\rho(k)^2}{T-k}$$

Sous H$_0$, la statistique $Q_K$ suit asymptotiquement un $\chi^2$ à $K$ degrés de liberté.

```{r echo=FALSE, message=FALSE, warning=FALSE}
Box.test(ts, lag = 1, type = "Ljung-Box")
```

Notre série est autocorrélée à l'ordre $1$. On n'effectue pas d'autres tests à des ordres plus élevés puisque ces derniers seront également significatifs et n'apportent donc aucune nouvelle information. 

\

### EACF pour les $p$ et $q$ de départ du modèle ARMA(p,q)

```{r echo=FALSE, message=FALSE, warning=FALSE}
eacf(ts)
```

D'après les résultats de l'EACF, on décide de créer un premier modèle $ARMA(2,1)$


















\newpage

# Modélisation d'un ARMA(p,q)

```{r echo=TRUE, fig.align='left', message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
model = Arima(ts, order = c(4,0,4))
coeftest(model)
```


















\newpage

# Tests sur les résidus

On cherche à vérifier si les résidus issus de notre série sont des bruits blancs gaussiens. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
residuals = model$residuals
```

### Test d'espérance nulle

Afin de déterminer si l'espérance des aléas est nulle, on utilise la moyenne des résidus, notée $m(e)$, et on calcule un $t$ de Student. Le test effectué est le suivant :

- H$_0$ : $E(\varepsilon_t) = 0$
- H$_1$ : $E(\varepsilon_t) \neq 0$

La statistique de test utilisée est :
$$t = \frac{\mid m(e) \mid}{\sigma_e} \times \sqrt{T}$$

Sous H$_0$, la statistique $t$ suit asymptotiquement une $N(0,1)$.

```{r echo=TRUE, message=FALSE, warning=FALSE}
t.test(residuals)
```

Etant donné que $p>0.05$, on ne rejette pas l'hypothèse nulle d'espérance des aléas nulle. 

### Test d'autocorrélation

On cherche à savoir si notre modèle $ARMA(p,q)$ prend bien en compte toute l'autocorrélation de la série. S'il en reste dans les résidus, alors notre modèle modélise mal nos données et doit être ré-estimé. 

On effectue le test suivant :

- H$_0$ : $\rho(1) = \rho(2) = \dots = \rho(K) =0$
- H$_1$ : Au moins un des $\rho(k) \neq 0$

La statistique de test utilisée est :
$$Q_K = T(T+1) \sum_{k=1}^{K} \frac{\hat\rho(k)^2}{T-k}$$

Sous H$_0$, la statistique $Q_K$ suit asymptotiquement un $\chi^2$ à $K$ degrés de liberté.

```{r echo=TRUE, message=FALSE, warning=FALSE}
Box.test(residuals, lag = 10)
```

### Test de normalité

Afin de savoir si les conclusions tirées sur nos coefficients estimés sont valides, on cherche à savoir si les aléas sont normalement distribués. Pour cela, on effectue un test de Jarque-Bera sur les résidus. On test alors :

- H$_0$ : normalité des données
- H$_1$ : non-normalité des données

La statistique de test utilisée est :
$$JB = \frac{n-k}{6}\times (S^2 + \frac{(K-2)^2}{4})$$
avec $S$ le coefficient d'asymétrie (*skewness*) et $K$ le coefficient d'applatissement (*kurtosis*).

Sous H$_0$, la statistique $JB$ suit asymptotiquement un $\chi^2$ à $2$ degrés de liberté.

```{r echo=TRUE, message=FALSE, warning=FALSE}
jarque.bera.test(residuals)
```

La p-value associée à la valeur de test étant supérieure au seuil de $5\%$, on ne rejette pas l'hypothèse nulle de normalité des données. Nos inférences précédentes sont alors valides et on peut s'en servir pour faire de la prévision. 

















\newpage

# Prévision

### Prédiction sur 5 ans, de 2022 à 2026

```{r echo=FALSE, message=FALSE, warning=FALSE}
h = 5
prev = forecast(model, h=h, level=0.95)
prev = data.frame(prev)
prev$Date = rownames(prev)
colnames(prev)[1] = "Saving rate"
savings$Lo.95 = NA
savings$Hi.95 = NA
all = rbind(savings, prev)
all$Date = as.integer(all$Date)
rownames(all) = 1:nrow(all)
last = tail(all, h)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
all %>%
  ggplot(aes(x=Date, y=`Saving rate`)) +
  geom_line() +
  geom_ribbon(data = last, aes(x = Date, ymin = Lo.95, ymax = Hi.95), fill = "lightblue", alpha = 0.5) +
  xlab("Date") +
  ylab("Value") +
  ylim(c(20,33)) + 
  theme_bw()
```









\newpage

# Annexe 

### Test de Dickey-Fuller avec critère de sélection BIC

```{r echo=TRUE, fig.align='center', message=FALSE, warning=FALSE}
summary(ur.df(ts, type = "trend", lags = pmax, selectlags = "BIC"))
plot(ur.df(ts, type = "trend", lags = pmax, selectlags = "BIC"))
```

Cette spécification ne permettant pas de prendre en compte toute l'autocorrélation présente dans les résidus, on ne la conserve pas. 

### Test de Zivot-Andrews avec spécification "both"

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(ur.za(ts, model="both", lag=pmax-1))
```

La statistique associée à $DT$ n'étant pas significative ($p>0.05$), on ne garde pas cette spécification. 




\newpage

# References

1. [Natural gas balance sheet; supply and consumption](https://opendata.cbs.nl/statline/#/CBS/en/dataset/00372eng/table?ts=1550090436913)

2. [Corden, W. M., & Neary, J. P. (1982). Booming sector and de-industrialisation in a small open economy. The economic journal, 92(368), 825-848.](https://academic.oup.com/ej/article/92/368/825/5220457)





\
\
\
\
\
\
\
\
\
\
\
\